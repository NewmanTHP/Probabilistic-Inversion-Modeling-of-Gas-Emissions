{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chilbolton Source 1 Inversion\n",
    "-------------------------------\n",
    "\n",
    "This notebook was used to produce the Source 1 parameter estimation results in Section 5 and Supplementary Material B 2.5. These are presented in the notebook: \"Chilbolton sources inversion results.ipynb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>PACKAGE REQUIREMENT:</b> Package \"sourceinversion\". Install using:<br>\n",
    "pip install -q sourceinversion\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q sourceinversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>DATA:</b> Need to replace data file paths with your own local path. The files are all located in the folder:<br>\n",
    "Paper 1: Code/Data/...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing \"sourceinversion\" Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 09:46:55.938361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sourceinversion.atmospheric_measurements as gp\n",
    "import sourceinversion.mcmc as mcmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jax.flatten_util import ravel_pytree\n",
    "import jax.numpy as jnp\n",
    "from jax import config\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "tfd = tfp.distributions\n",
    "import itertools\n",
    "from jax import lax\n",
    "from pyDOE import lhs\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Chilbolton Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>DATA:</b> Need to replace data file paths with your own local path. The files are all located in the folder:<br>\n",
    "Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Source_1/Chilbolton_CH4_measurements_source_1.pkl\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 CH4 measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Measurements\n",
      "0        2.957493\n",
      "1        3.225206\n",
      "2        3.019588\n",
      "3        3.879900\n",
      "4        4.447954\n",
      "..            ...\n",
      "968      4.647827\n",
      "969      3.454171\n",
      "970      3.486773\n",
      "971      3.936550\n",
      "972      4.464640\n",
      "\n",
      "[973 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('/home/newmant1/PhD/Packages/Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Source_1/Chilbolton_CH4_measurements_source_1.pkl', 'rb') as f:\n",
    "    observations = pickle.load(f)\n",
    "\n",
    "print(observations)\n",
    "data = observations.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Wind field and rolling standard deviation of the horizontal and vertical wind direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>DATA:</b> Need to replace data file paths with your own local path. The files are all located in the folder:<br>\n",
    "Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Source_1/Chilbolton_windfield_source_1.pkl\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Average Speed  Average Direction\n",
      "0         2.529329         226.166649\n",
      "1         2.939350         215.829043\n",
      "2         2.722847         217.057046\n",
      "3         2.953901         202.037573\n",
      "4         2.350180         223.174301\n",
      "..             ...                ...\n",
      "134       2.350765         164.940863\n",
      "135       2.309250         162.287127\n",
      "136       2.422438         177.557325\n",
      "137       2.256529         168.427323\n",
      "138       2.794600         161.861761\n",
      "\n",
      "[139 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('/home/newmant1/PhD/Packages/Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Source_1/Chilbolton_windfield_source_1.pkl', 'rb') as f:\n",
    "    tangamma_ts = pickle.load(f)\n",
    "    wind_field = tangamma_ts[['Average Speed', 'Average Direction']]\n",
    "print(wind_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Sensor layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>DATA:</b> Need to replace data file paths with your own local path. The files are all located in the folder:<br>\n",
    "Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Sensor_reflector_locations/Chilbolton_instruments_location.pkl\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/newmant1/PhD/Packages/Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Sensor_reflector_locations/Chilbolton_instruments_location.pkl', 'rb') as f:\n",
    "    instruments_location = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating integration points along beam every 0.40 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_point_sensors = {\n",
    "    \"reflector_1\": 18*5,\n",
    "    \"reflector_2\": 33*5,\n",
    "    \"reflector_3\": 22*5,\n",
    "    \"reflector_4\": 49*5,\n",
    "    \"reflector_5\": 42*5,\n",
    "    \"reflector_6\": 29*5,\n",
    "    \"reflector_7\": 17*5,\n",
    "}\n",
    "\n",
    "def get_equally_spaced_points(point1, point2, num_points):\n",
    "    # Calculate the step size for each dimension\n",
    "    step_size = [(p2 - p1) / (num_points - 1) for p1, p2 in zip(point1, point2)]\n",
    "\n",
    "    # Calculate the coordinates of the equally spaced points\n",
    "    points = [[p1 + i * step for p1, step in zip(point1, step_size)] for i in range(num_points)]\n",
    "\n",
    "    return points\n",
    "\n",
    "point_sensors_1_location = get_equally_spaced_points(instruments_location[\"line_of_sight_sensor\"], instruments_location[\"reflector_1\"], number_of_point_sensors[\"reflector_1\"])\n",
    "point_sensors_2_location = get_equally_spaced_points(instruments_location[\"line_of_sight_sensor\"], instruments_location[\"reflector_2\"], number_of_point_sensors[\"reflector_2\"])\n",
    "point_sensors_3_location = get_equally_spaced_points(instruments_location[\"line_of_sight_sensor\"], instruments_location[\"reflector_3\"], number_of_point_sensors[\"reflector_3\"])\n",
    "point_sensors_4_location = get_equally_spaced_points(instruments_location[\"line_of_sight_sensor\"], instruments_location[\"reflector_4\"], number_of_point_sensors[\"reflector_4\"])\n",
    "point_sensors_5_location = get_equally_spaced_points(instruments_location[\"line_of_sight_sensor\"], instruments_location[\"reflector_5\"], number_of_point_sensors[\"reflector_5\"])\n",
    "point_sensors_6_location = get_equally_spaced_points(instruments_location[\"line_of_sight_sensor\"], instruments_location[\"reflector_6\"], number_of_point_sensors[\"reflector_6\"])\n",
    "point_sensors_7_location = get_equally_spaced_points(instruments_location[\"line_of_sight_sensor\"], instruments_location[\"reflector_7\"], number_of_point_sensors[\"reflector_7\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>DATA:</b> Need to replace data file paths with your own local path. The files are all located in the folder:<br>\n",
    "Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Source_locations_and_emission_rates/Chilbolton_sources_locations_and_emission_rates.pkl\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/newmant1/PhD/Packages/Paper 1: Code/Data/Chilbolton_data_files/Postprocessed/Source_locations_and_emission_rates/Chilbolton_sources_locations_and_emission_rates.pkl', 'rb') as f:\n",
    "    sources = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up for Inversion using \"sourceinversion\" package\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Variables set to \"None\" are used only when simulating gas emissions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Grid specification based on the Chilbolton terrain dimensions (used for Grid-based inversion)\n",
    "grid = gp.Grid(\n",
    "    x_range = (jnp.array(40.0), jnp.array(80.0)), \n",
    "    y_range = (jnp.array(0.0), jnp.array(110.0)),\n",
    "    z_range= (jnp.array(0.0), jnp.array(0.0)),\n",
    "    dx = jnp.array(10),\n",
    "    dy = jnp.array(10),\n",
    "    dz = jnp.array(1),\n",
    ")\n",
    "\n",
    "\n",
    "# Source 1 location\n",
    "source_location = gp.SourceLocation(\n",
    "    source_location_x = jnp.array([sources[\"source_1_location\"][0]]),\n",
    "    source_location_y = jnp.array([sources[\"source_1_location\"][1]]),\n",
    "    source_location_z = jnp.array([sources[\"source_1_location\"][2]]),\n",
    ")\n",
    "\n",
    "\n",
    "# Atmospheric state\n",
    "atmospheric_state = gp.AtmosphericState(\n",
    "    emission_rate = jnp.array(sources[\"source_1_emission_rate\"]),              \n",
    "    source_half_width = jnp.array(1.0),                                 # Source is a square of 2m side length\n",
    "    max_abl = jnp.array(1000.0),\n",
    "    background_mean = None,                                  \n",
    "    background_std = None,       \n",
    "    background_seed = None,\n",
    "    background_filter = None,        \n",
    "    Gaussian_filter_kernel = None,              \n",
    "    horizontal_opening_angle= None,\n",
    "    vertical_opening_angle = None,\n",
    "    a_horizontal = None,\n",
    "    a_vertical = None,          \n",
    "    b_horizontal = None,         \n",
    "    b_vertical = None,        \n",
    ")\n",
    "\n",
    "# Sensor layout\n",
    "def flatten_list_of_lists(list_of_lists):\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "sensors_settings =  gp.SensorsSettings(\n",
    "    layout = None,\n",
    "    sensor_number = jnp.array(7),\n",
    "    measurement_error_var = None,\n",
    "    sensor_seed = None,\n",
    "    measurement_error_seed = None,\n",
    "    sensor_locations =  flatten_list_of_lists([point_sensors_1_location, point_sensors_2_location, point_sensors_3_location, point_sensors_4_location, point_sensors_5_location, point_sensors_6_location, point_sensors_7_location]), \n",
    ")\n",
    "\n",
    "\n",
    "# Gaussian Plume model\n",
    "gaussianplume = gp.GaussianPlume(grid, source_location, wind_field, atmospheric_state, sensors_settings)\n",
    "\n",
    "fixed  = gaussianplume.fixed_objects_of_gridfree_chilbolton_coupling_matrix(simulation = False, wind_direction=wind_field[\"Average Direction\"].values, wind_speed=wind_field[\"Average Speed\"].values, tangamma_ts = tangamma_ts, number_of_time_steps=wind_field.shape[0])\n",
    "fixed_ref1 = fixed[0], fixed[7], fixed[14], fixed[15], fixed[35], fixed[36], fixed[16], fixed[37], fixed[44]\n",
    "fixed_ref2 = fixed[1], fixed[8], fixed[17], fixed[18], fixed[35], fixed[36], fixed[19], fixed[38], fixed[45]\n",
    "fixed_ref3 = fixed[2], fixed[9], fixed[20], fixed[21], fixed[35], fixed[36], fixed[22], fixed[39], fixed[46]\n",
    "fixed_ref4 = fixed[3], fixed[10], fixed[23], fixed[24], fixed[35], fixed[36], fixed[25], fixed[40], fixed[47]\n",
    "fixed_ref5 = fixed[4], fixed[11], fixed[26], fixed[27], fixed[35], fixed[36], fixed[28], fixed[41], fixed[48]\n",
    "fixed_ref6 = fixed[5], fixed[12], fixed[29], fixed[30], fixed[35], fixed[36], fixed[31], fixed[42], fixed[49]\n",
    "fixed_ref7 = fixed[6], fixed[13], fixed[32], fixed[33], fixed[35], fixed[36], fixed[34], fixed[43], fixed[50]\n",
    "\n",
    "\n",
    "# Parameter priors\n",
    "priors = mcmc.Priors(\n",
    "    # Slab allocation rate prior (used in grid-based inversion)\n",
    "    theta = 0.1,\n",
    "\n",
    "    # Emission rate (log(s)): Log scale Slab and spike prior (used in grid-based inversion)\n",
    "    log_spike_mean = -25.0,\n",
    "    log_spike_var = 10.0,\n",
    "    log_slab_mean = -7.5,\n",
    "    log_slab_var = 1.5,\n",
    "\n",
    "    # Source location (x,y):\n",
    "    source_location_x_mean = 50.0,\n",
    "    source_location_x_var = 25.0,\n",
    "    source_location_y_mean = 50.0,\n",
    "    source_location_y_var = 25.0,\n",
    "\n",
    "    # Measurement error variance (sigma squared)\n",
    "    sigma_squared_con = 1e-11,\n",
    "    sigma_squared_rate = 1e-8,\n",
    "\n",
    "    # Background gas concentration (beta)\n",
    "    mean_background_prior = 1.92,\n",
    "    variance_background_prior = 0.1**2,\n",
    "\n",
    "    # Dispersion parameter (a_H, a_V, b_H, b_V)\n",
    "    a_mean = jnp.log(0.6),\n",
    "    a_var = 0.5**2,\n",
    "    b_mean = jnp.log(0.6),\n",
    "    b_var = 0.2**2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Source 1 Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Grid Search\n",
    "\n",
    "Here we only estimate source emission rate and location while fixing background gas concentration, measurement error variance and dispersion parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.    , 0.0002, 0.0004, 0.0006, 0.0008]),\n",
       " Array([40., 50., 60., 70., 80.], dtype=float64),\n",
       " Array([  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.,\n",
       "        110.], dtype=float64)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_granulaty_in_kg_per_s = 0.0002\n",
    "\n",
    "s_range = np.arange(0, 0.001, emission_granulaty_in_kg_per_s)\n",
    "x_range = grid.x\n",
    "y_range = grid.y\n",
    "\n",
    "ranges = []\n",
    "ranges.append(s_range)\n",
    "ranges.append(x_range)\n",
    "ranges.append(y_range)\n",
    "\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_likelihood(s, x, y, initial_sgm, initial_betas, scheme, stability_class, number_time_steps):\n",
    "    \"\"\"\n",
    "    Returns the positive log posterior of the point sensors measurements model. \n",
    "\n",
    "    \"\"\"\n",
    "    if stability_class == False:\n",
    "        stability_class = None\n",
    "        estimated = True\n",
    "    else:\n",
    "        estimated = False\n",
    "        \n",
    "    coupling_matrix_ref1 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref1, x, y, None, 1.0, 1.0, 1.0, 1.0, simulation=False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref2 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref2, x, y, None, 1.0, 1.0, 1.0, 1.0, simulation=False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref3 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref3, x, y, None, 1.0, 1.0, 1.0, 1.0, simulation=False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref4 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref4, x, y, None, 1.0, 1.0, 1.0, 1.0, simulation=False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref5 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref5, x, y, None, 1.0, 1.0, 1.0, 1.0, simulation=False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref6 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref6, x, y, None, 1.0, 1.0, 1.0, 1.0, simulation=False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref7 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref7, x, y, None, 1.0, 1.0, 1.0, 1.0, simulation=False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    \n",
    "\n",
    "    reshaped_coupling_matrix_ref1 = coupling_matrix_ref1.reshape(number_time_steps,18*5, order='F')\n",
    "    reshaped_coupling_matrix_ref2 = coupling_matrix_ref2.reshape(number_time_steps,33*5, order='F')\n",
    "    reshaped_coupling_matrix_ref3 = coupling_matrix_ref3.reshape(number_time_steps,22*5, order='F')\n",
    "    reshaped_coupling_matrix_ref4 = coupling_matrix_ref4.reshape(number_time_steps,49*5, order='F')\n",
    "    reshaped_coupling_matrix_ref5 = coupling_matrix_ref5.reshape(number_time_steps,42*5, order='F')\n",
    "    reshaped_coupling_matrix_ref6 = coupling_matrix_ref6.reshape(number_time_steps,29*5, order='F')\n",
    "    reshaped_coupling_matrix_ref7 = coupling_matrix_ref7.reshape(number_time_steps,17*5, order='F')\n",
    "\n",
    "    path_averaged_coupling_matrix_ref1 = reshaped_coupling_matrix_ref1.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref2 = reshaped_coupling_matrix_ref2.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref3 = reshaped_coupling_matrix_ref3.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref4 = reshaped_coupling_matrix_ref4.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref5 = reshaped_coupling_matrix_ref5.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref6 = reshaped_coupling_matrix_ref6.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref7 = reshaped_coupling_matrix_ref7.mean(axis=1)\n",
    "\n",
    "    path_averaged_A = [path_averaged_coupling_matrix_ref1, path_averaged_coupling_matrix_ref2, path_averaged_coupling_matrix_ref3, path_averaged_coupling_matrix_ref4, path_averaged_coupling_matrix_ref5, path_averaged_coupling_matrix_ref6, path_averaged_coupling_matrix_ref7]\n",
    "    A = jnp.array(path_averaged_A).reshape(-1,1)\n",
    "\n",
    "    log_likelihood = tfd.Normal(loc = (jnp.matmul(A,s.reshape(-1,1)) + jnp.repeat(initial_betas, number_time_steps).reshape(-1,1)), \\\n",
    "                                scale= jnp.sqrt(initial_sgm)).log_prob(data)\n",
    "\n",
    "    log_posterior = jnp.sum(log_likelihood) \n",
    "\n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter combinations: 300\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations of parameters\n",
    "sources_param = jnp.zeros(len(ranges))\n",
    "parameter_combinations = jnp.array(list(itertools.product(*ranges[:len(ranges)+1])))\n",
    "print(f\"Number of parameter combinations: {parameter_combinations.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search maximum likelihood estimation of emission rate and location:\n",
      "          s     x     y\n",
      "165  0.0004  70.0  90.0\n"
     ]
    }
   ],
   "source": [
    "# Initial parameter values for:\n",
    "\n",
    "# Sensor measurement error variance\n",
    "initial_sgm = 1e-5\n",
    "# Background gas concentration\n",
    "initial_betas = jnp.repeat(1.92, 7)\n",
    "\n",
    "# Step function\n",
    "def one_step(_, parameters):\n",
    "    s, x, y= parameters[::3], parameters[1::3], parameters[2::3]\n",
    "    new_likelihood = search_likelihood(s,x,y, initial_sgm, initial_betas, \"Draxler\", False, wind_field.shape[0]) \n",
    "    return new_likelihood, new_likelihood\n",
    "# Use lax.scan to iterate over the parameter combinations\n",
    "_, likelihoods = lax.scan(one_step, 0.0, parameter_combinations)\n",
    "# Analysing output\n",
    "likelihood_df = pd.DataFrame(likelihoods, columns = ['log_likelihood'])\n",
    "parameters_df = pd.DataFrame(parameter_combinations, columns = [\"s\", \"x\", \"y\"])\n",
    "max_likelihood_index = likelihood_df.idxmax()\n",
    "max_likelihood_row = parameters_df.iloc[max_likelihood_index]\n",
    "sources_param = sources_param.at[:].set(max_likelihood_row.values.flatten())\n",
    "print(f\"Grid search maximum likelihood estimation of emission rate and location:\")\n",
    "print(max_likelihood_row)\n",
    "\n",
    "rates = max_likelihood_row.values.flatten()[0]\n",
    "loc_x = max_likelihood_row.values.flatten()[1]\n",
    "loc_y = max_likelihood_row.values.flatten()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Latin Hypercube\n",
    "\n",
    "Here we estimate all parameters simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin Hypercube maximum likelihood estimation:\n",
      "          s_1        x_1       y_1      sgm       a_h       a_v       b_h  \\\n",
      "945  0.000394  70.566481  89.17019  0.00009  0.808232  0.754779  0.968559   \n",
      "\n",
      "          b_v  \n",
      "945  0.862599  \n"
     ]
    }
   ],
   "source": [
    "def latin_hypercube_sampling(param_ranges, num_samples):\n",
    "    \"\"\"\n",
    "    Generate a Latin Hypercube Sample within specified parameter ranges.\n",
    "\n",
    "    Parameters:\n",
    "    param_ranges (list of tuple): A list of tuples specifying the range (min, max) for each parameter.\n",
    "    num_samples (int): The number of samples to generate.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A num_samples x num_params matrix where each column corresponds to a parameter and each row corresponds to a sample.\n",
    "    \"\"\"\n",
    "    num_params = len(param_ranges)\n",
    "    \n",
    "    # Generate the Latin Hypercube Sample\n",
    "    lhd = lhs(num_params, num_samples)\n",
    "    \n",
    "    # Scale the samples to be within the parameter ranges\n",
    "    for i in range(num_params):\n",
    "        min_val, max_val = param_ranges[i]\n",
    "        lhd[:, i] = lhd[:, i] * (max_val - min_val) + min_val\n",
    "\n",
    "    return lhd\n",
    "\n",
    "\n",
    "def latin_hypercube_likelihood(s, x, y, sgm, a_h, a_v, b_h, b_v, scheme, stability_class, number_time_steps):\n",
    "    \"\"\"\n",
    "    Returns the positive log posterior of the point sensors measurements model. \n",
    "\n",
    "    \"\"\"\n",
    "    if stability_class == False:\n",
    "        stability_class = None\n",
    "        estimated = True\n",
    "    else:\n",
    "        estimated = False\n",
    "\n",
    "    coupling_matrix_ref1 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref1, x, y, None, jnp.array(a_h), jnp.array(a_v), jnp.array(b_h), jnp.array(b_v), simulation = False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref2 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref2, x, y, None, jnp.array(a_h), jnp.array(a_v), jnp.array(b_h), jnp.array(b_v), simulation = False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref3 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref3, x, y, None, jnp.array(a_h), jnp.array(a_v), jnp.array(b_h), jnp.array(b_v), simulation = False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref4 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref4, x, y, None, jnp.array(a_h), jnp.array(a_v), jnp.array(b_h), jnp.array(b_v), simulation = False, estimated=estimated, scheme=scheme, stability_class=stability_class)    \n",
    "    coupling_matrix_ref5 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref5, x, y, None, jnp.array(a_h), jnp.array(a_v), jnp.array(b_h), jnp.array(b_v), simulation = False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref6 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref6, x, y, None, jnp.array(a_h), jnp.array(a_v), jnp.array(b_h), jnp.array(b_v), simulation = False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    coupling_matrix_ref7 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref7, x, y, None, jnp.array(a_h), jnp.array(a_v), jnp.array(b_h), jnp.array(b_v), simulation = False, estimated=estimated, scheme=scheme, stability_class=stability_class)\n",
    "    \n",
    "\n",
    "    reshaped_coupling_matrix_ref1 = coupling_matrix_ref1.reshape(number_time_steps,18*5, order='F')\n",
    "    reshaped_coupling_matrix_ref2 = coupling_matrix_ref2.reshape(number_time_steps,33*5, order='F')\n",
    "    reshaped_coupling_matrix_ref3 = coupling_matrix_ref3.reshape(number_time_steps,22*5, order='F')\n",
    "    reshaped_coupling_matrix_ref4 = coupling_matrix_ref4.reshape(number_time_steps,49*5, order='F')\n",
    "    reshaped_coupling_matrix_ref5 = coupling_matrix_ref5.reshape(number_time_steps,42*5, order='F')\n",
    "    reshaped_coupling_matrix_ref6 = coupling_matrix_ref6.reshape(number_time_steps,29*5, order='F')\n",
    "    reshaped_coupling_matrix_ref7 = coupling_matrix_ref7.reshape(number_time_steps,17*5, order='F')\n",
    "\n",
    "    path_averaged_coupling_matrix_ref1 = reshaped_coupling_matrix_ref1.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref2 = reshaped_coupling_matrix_ref2.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref3 = reshaped_coupling_matrix_ref3.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref4 = reshaped_coupling_matrix_ref4.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref5 = reshaped_coupling_matrix_ref5.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref6 = reshaped_coupling_matrix_ref6.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref7 = reshaped_coupling_matrix_ref7.mean(axis=1)\n",
    "\n",
    "    path_averaged_A = [path_averaged_coupling_matrix_ref1, path_averaged_coupling_matrix_ref2, path_averaged_coupling_matrix_ref3, path_averaged_coupling_matrix_ref4, path_averaged_coupling_matrix_ref5, path_averaged_coupling_matrix_ref6, path_averaged_coupling_matrix_ref7]\n",
    "    A = jnp.array(path_averaged_A).reshape(-1,1)\n",
    "\n",
    "    log_likelihood = tfd.Normal(loc = (jnp.matmul(A, s.reshape(-1,1)) + jnp.repeat(initial_betas, number_time_steps).reshape(-1,1)), \\\n",
    "                                scale= jnp.sqrt(sgm)).log_prob(data) \n",
    "    \n",
    "    log_posterior = jnp.sum(log_likelihood)\n",
    "\n",
    "    return log_posterior\n",
    "\n",
    "param_ranges = []\n",
    "param_ranges.append((np.maximum(0, rates - emission_granulaty_in_kg_per_s), rates + emission_granulaty_in_kg_per_s))\n",
    "param_ranges.append((loc_x - grid.dx, loc_x + grid.dx))\n",
    "param_ranges.append((loc_y - grid.dy, loc_y + grid.dy))\n",
    "\n",
    "param_ranges.append((0, 1e-4))\n",
    "param_ranges.append((0.5, 1.2))\n",
    "param_ranges.append((0.5, 1.2))\n",
    "param_ranges.append((0.5, 1.01))\n",
    "param_ranges.append((0.5, 1.01))\n",
    "\n",
    "\n",
    "num_samples = 1_000\n",
    "lh_samples = latin_hypercube_sampling(param_ranges, num_samples)\n",
    "# Step function\n",
    "def lh_one_step(_, parameters):\n",
    "    rates = jnp.zeros(int(len(ranges)/3))\n",
    "    loc_x = jnp.zeros(int(len(ranges)/3))\n",
    "    loc_y = jnp.zeros(int(len(ranges)/3))\n",
    "    for source_nbr in range(int(len(ranges)/3)):\n",
    "        rates = rates.at[source_nbr].set(parameters[source_nbr*3])\n",
    "        loc_x = loc_x.at[source_nbr].set(parameters[source_nbr*3+1])\n",
    "        loc_y = loc_y.at[source_nbr].set(parameters[source_nbr*3+2])\n",
    "    sgm, a_h, a_v, b_h, b_v = parameters[int(len(ranges)):]\n",
    "    new_likelihood = latin_hypercube_likelihood(rates, loc_x, loc_y, sgm, a_h, a_v, b_h, b_v, \"Draxler\", False, wind_field.shape[0])\n",
    "    return new_likelihood, new_likelihood\n",
    "# Use lax.scan to iterate over the parameter combinations\n",
    "_, lh_likelihoods = lax.scan(lh_one_step, 0.0, lh_samples)\n",
    "\n",
    "# Analysing output\n",
    "lh_likelihood_df = pd.DataFrame(lh_likelihoods, columns = ['log_likelihood'])\n",
    "lh_parameters_df = pd.DataFrame(lh_samples, columns = list(itertools.chain(*[['s_' + str(i+1), 'x_' + str(i+1), 'y_' + str(i+1)] for i in range(int(len(ranges)/3))])) + ['sgm', 'a_h', 'a_v', 'b_h', 'b_v'])\n",
    "lh_max_likelihood_index = lh_likelihood_df.idxmax()\n",
    "lh_max_likelihood_row = lh_parameters_df.iloc[lh_max_likelihood_index]\n",
    "print(f\"Latin Hypercube maximum likelihood estimation:\")\n",
    "print(lh_max_likelihood_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Manifold-Metropolis-within-Gibbs\n",
    "\n",
    "Here we estimate all parameters simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Initial Parameter Values:\n",
      "--------------------------------\n",
      "Initial log rates: [-7.92908941]\n",
      "Initial locations x: [70.05841705]\n",
      "Initial locations y: [89.76965449]\n",
      "Initial sgm sqr: 9.979351618228309e-05\n",
      "Initial log a_h: 0.17009069463291984\n",
      "Initial log a_v: 0.10470436312557482\n",
      "Initial log b_h: -0.42661750336364923\n",
      "Initial log b_v: -0.44613421848388085\n"
     ]
    }
   ],
   "source": [
    "initial_log_rates = jnp.log(lh_max_likelihood_row[['s_' + str(i+1) for i in range(int(len(ranges)/3))]].values.flatten())\n",
    "initial_locations_x = lh_max_likelihood_row[['x_' + str(i+1) for i in range(int(len(ranges)/3))]].values.flatten()\n",
    "initial_locations_y = lh_max_likelihood_row[['y_' + str(i+1) for i in range(int(len(ranges)/3))]].values.flatten()\n",
    "initial_sgm_sqr = lh_max_likelihood_row.values.flatten()[3]\n",
    "initial_log_a_h = jnp.log(lh_max_likelihood_row.values.flatten()[4])\n",
    "initial_log_a_v = jnp.log(lh_max_likelihood_row.values.flatten()[5])\n",
    "initial_log_b_h = jnp.log(lh_max_likelihood_row.values.flatten()[6])\n",
    "initial_log_b_v = jnp.log(lh_max_likelihood_row.values.flatten()[7])\n",
    "\n",
    "print(f\"Setting Initial Parameter Values:\")\n",
    "print(f\"--------------------------------\")\n",
    "print(f\"Initial log rates: {initial_log_rates}\")\n",
    "print(f\"Initial locations x: {initial_locations_x}\")\n",
    "print(f\"Initial locations y: {initial_locations_y}\")\n",
    "print(f\"Initial sgm sqr: {initial_sgm_sqr}\")\n",
    "print(f\"Initial log a_h: {initial_log_a_h}\")\n",
    "print(f\"Initial log a_v: {initial_log_a_v}\")\n",
    "print(f\"Initial log b_h: {initial_log_b_h}\")\n",
    "print(f\"Initial log b_v: {initial_log_b_v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gibbsparams = {\n",
    "    'background': initial_betas,\n",
    "    'sigma_squared':   initial_sgm_sqr,\n",
    "}\n",
    "gibbs_flat, gibbs_unflat_func = ravel_pytree(Gibbsparams)\n",
    "\n",
    "MHparams = {\n",
    "    'log_a_H': initial_log_a_h,\n",
    "    'log_a_V': initial_log_a_v,\n",
    "    'log_b_H':  initial_log_b_h,\n",
    "    'log_b_V': initial_log_b_v,\n",
    "    'log_s': jnp.array(initial_log_rates),\n",
    "    'source_x': jnp.array(initial_locations_x),\n",
    "    'source_y': jnp.array(initial_locations_y),\n",
    "    }\n",
    "mh_flat, mh_unflat_func = ravel_pytree(MHparams)\n",
    "\n",
    "\n",
    "def log_posterior(params, sigma_squared, betas, ss_var, ss_mean, data, priors, wind_sigma, number_of_time_steps):\n",
    "    \"\"\"\n",
    "    Returns the positive log posterior of the point sensors measurements model. \n",
    "\n",
    "    \"\"\"\n",
    "    if wind_sigma == True:\n",
    "        coupling_matrix_ref1 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref1, params[\"source_x\"], params[\"source_y\"], None, jnp.exp(params[\"log_a_H\"]), jnp.exp(params[\"log_a_V\"]), jnp.exp(params[\"log_b_H\"]), jnp.exp(params[\"log_b_V\"]), simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref2 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref2, params[\"source_x\"], params[\"source_y\"], None, jnp.exp(params[\"log_a_H\"]), jnp.exp(params[\"log_a_V\"]), jnp.exp(params[\"log_b_H\"]), jnp.exp(params[\"log_b_V\"]), simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref3 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref3, params[\"source_x\"], params[\"source_y\"], None, jnp.exp(params[\"log_a_H\"]), jnp.exp(params[\"log_a_V\"]), jnp.exp(params[\"log_b_H\"]), jnp.exp(params[\"log_b_V\"]), simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref4 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref4, params[\"source_x\"], params[\"source_y\"], None, jnp.exp(params[\"log_a_H\"]), jnp.exp(params[\"log_a_V\"]), jnp.exp(params[\"log_b_H\"]), jnp.exp(params[\"log_b_V\"]), simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref5 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref5, params[\"source_x\"], params[\"source_y\"], None, jnp.exp(params[\"log_a_H\"]), jnp.exp(params[\"log_a_V\"]), jnp.exp(params[\"log_b_H\"]), jnp.exp(params[\"log_b_V\"]), simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref6 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref6, params[\"source_x\"], params[\"source_y\"], None, jnp.exp(params[\"log_a_H\"]), jnp.exp(params[\"log_a_V\"]), jnp.exp(params[\"log_b_H\"]), jnp.exp(params[\"log_b_V\"]), simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref7 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref7, params[\"source_x\"], params[\"source_y\"], None, jnp.exp(params[\"log_a_H\"]), jnp.exp(params[\"log_a_V\"]), jnp.exp(params[\"log_b_H\"]), jnp.exp(params[\"log_b_V\"]), simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "    elif wind_sigma == False:\n",
    "        coupling_matrix_ref1 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref1,params[\"source_x\"],params[\"source_y\"], None, False, False, False, False, simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref2 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref2,params[\"source_x\"],params[\"source_y\"], None, False, False, False, False, simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref3 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref3,params[\"source_x\"],params[\"source_y\"], None, False, False, False, False, simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref4 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref4,params[\"source_x\"],params[\"source_y\"], None, False, False, False, False, simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref5 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref5,params[\"source_x\"],params[\"source_y\"], None, False, False, False, False, simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref6 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref6,params[\"source_x\"],params[\"source_y\"], None, False, False, False, False, simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "        coupling_matrix_ref7 = gaussianplume.temporal_gridfree_coupling_matrix(fixed_ref7,params[\"source_x\"],params[\"source_y\"], None, False, False, False, False, simulation = False, estimated=True, scheme=\"Draxler\", stability_class=\"D\")\n",
    "\n",
    "    reshaped_coupling_matrix_ref1 = coupling_matrix_ref1.reshape(number_of_time_steps,18*5, order='F')\n",
    "    reshaped_coupling_matrix_ref2 = coupling_matrix_ref2.reshape(number_of_time_steps,33*5, order='F')\n",
    "    reshaped_coupling_matrix_ref3 = coupling_matrix_ref3.reshape(number_of_time_steps,22*5, order='F')\n",
    "    reshaped_coupling_matrix_ref4 = coupling_matrix_ref4.reshape(number_of_time_steps,49*5, order='F')\n",
    "    reshaped_coupling_matrix_ref5 = coupling_matrix_ref5.reshape(number_of_time_steps,42*5, order='F')\n",
    "    reshaped_coupling_matrix_ref6 = coupling_matrix_ref6.reshape(number_of_time_steps,29*5, order='F')\n",
    "    reshaped_coupling_matrix_ref7 = coupling_matrix_ref7.reshape(number_of_time_steps,17*5, order='F')\n",
    "\n",
    "    path_averaged_coupling_matrix_ref1 = reshaped_coupling_matrix_ref1.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref2 = reshaped_coupling_matrix_ref2.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref3 = reshaped_coupling_matrix_ref3.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref4 = reshaped_coupling_matrix_ref4.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref5 = reshaped_coupling_matrix_ref5.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref6 = reshaped_coupling_matrix_ref6.mean(axis=1)\n",
    "    path_averaged_coupling_matrix_ref7 = reshaped_coupling_matrix_ref7.mean(axis=1)\n",
    "\n",
    "    path_averaged_A = [path_averaged_coupling_matrix_ref1, path_averaged_coupling_matrix_ref2, path_averaged_coupling_matrix_ref3, path_averaged_coupling_matrix_ref4, path_averaged_coupling_matrix_ref5, path_averaged_coupling_matrix_ref6, path_averaged_coupling_matrix_ref7]\n",
    "    A = jnp.array(path_averaged_A).reshape(-1,1)\n",
    "\n",
    "    log_likelihood = tfd.Normal(loc = (jnp.matmul(A,jnp.exp(params[\"log_s\"]).reshape(-1,1))+ betas), \\\n",
    "                                scale= jnp.sqrt(sigma_squared)).log_prob(data)\n",
    "\n",
    "    if wind_sigma == True:\n",
    "        log_prior_a_H = tfd.Normal(loc = priors.a_mean, scale = jnp.sqrt(priors.a_var)).log_prob(params[\"log_a_H\"])\n",
    "        log_prior_a_V = tfd.Normal(loc = priors.a_mean, scale = jnp.sqrt(priors.a_var)).log_prob(params[\"log_a_V\"])\n",
    "        log_prior_b_H = tfd.Normal(loc = priors.b_mean, scale = jnp.sqrt(priors.b_var)).log_prob(params[\"log_b_H\"])\n",
    "        log_prior_b_V = tfd.Normal(loc = priors.b_mean, scale = jnp.sqrt(priors.b_var)).log_prob(params[\"log_b_V\"])\n",
    "\n",
    "    log_posterior_emission_rate = tfd.MultivariateNormalDiag(loc = ss_mean, scale_diag = jnp.sqrt(ss_var)).log_prob(params[\"log_s\"].reshape(-1,1))\n",
    "    log_posterior_source_location = tfd.MultivariateNormalDiag(loc = jnp.array([priors.source_location_x_mean, priors.source_location_y_mean]), \\\n",
    "                                                                scale_diag = jnp.sqrt(jnp.array([priors.source_location_x_var, priors.source_location_y_var]))).log_prob(jnp.array([params[\"source_x\"], params[\"source_y\"]]).flatten())\n",
    "\n",
    "    if wind_sigma == True:\n",
    "        log_posterior = jnp.sum(log_likelihood) + jnp.sum(log_posterior_source_location) + jnp.sum(log_posterior_emission_rate) + jnp.sum(log_prior_a_H) + jnp.sum(log_prior_a_V) + jnp.sum(log_prior_b_H) + jnp.sum(log_prior_b_V) \n",
    "    elif wind_sigma == False:\n",
    "        log_posterior = jnp.sum(log_likelihood) + jnp.sum(log_posterior_source_location) + jnp.sum(log_posterior_emission_rate)\n",
    "\n",
    "    return log_posterior, A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10_000\n",
    "initial_step_size = 0.5\n",
    "# Run the MCMC algorithm\n",
    "mala_chains = mcmc.Manifold_MALA_Within_Gibbs(False, gaussianplume, data, log_posterior, priors, MHparams, Gibbsparams, fixed, chilbolton=True, wind_sigmas=True, release_17 = False, step_size_tuning=\"False\").manifold_mala_chains(Gibbsparams, mh_flat, iterations, initial_step_size, release_17=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 1, figsize=(17, 12))\n",
    "# fig.suptitle('Source 1 Models Predictions vs Observations', fontsize=20)\n",
    "\n",
    "# axs[0].plot(estimated_y_hat[:139])\n",
    "# axs[0].plot(SMITH_B_y_hat[:139])\n",
    "# axs[0].plot(SMITH_C_y_hat[:139])\n",
    "# axs[0].plot(SMITH_D_y_hat[:139])\n",
    "# axs[0].plot(Briggs_A_y_hat[:139])\n",
    "# axs[0].plot(Briggs_B_y_hat[:139])\n",
    "# axs[0].plot(Briggs_C_y_hat[:139])\n",
    "# axs[0].plot(Briggs_D_y_hat[:139])\n",
    "# axs[0].plot(Briggs_E_y_hat[:139])\n",
    "# axs[0].plot(Briggs_F_y_hat[:139])\n",
    "# axs[0].plot(est_SMITH_y_hat[:139])\n",
    "# axs[0].plot(observations.values[:139], linestyle='--', color='red', linewidth=2)\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 1')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[1].set_title('Wind Direction')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(17, 12))\n",
    "# fig.suptitle('Source 1 Models Predictions vs Observations', fontsize=20)\n",
    "\n",
    "# axs[0].plot(estimated_y_hat[139:139*2])\n",
    "# axs[0].plot(SMITH_B_y_hat[139:139*2])\n",
    "# axs[0].plot(SMITH_C_y_hat[139:139*2])\n",
    "# axs[0].plot(SMITH_D_y_hat[139:139*2])\n",
    "# axs[0].plot(Briggs_A_y_hat[139:139*2])\n",
    "# axs[0].plot(Briggs_B_y_hat[139:139*2])\n",
    "# axs[0].plot(Briggs_C_y_hat[139:139*2])\n",
    "# axs[0].plot(Briggs_D_y_hat[139:139*2])\n",
    "# axs[0].plot(Briggs_E_y_hat[139:139*2])\n",
    "# axs[0].plot(Briggs_F_y_hat[139:139*2])\n",
    "# axs[0].plot(est_SMITH_y_hat[139:139*2])\n",
    "# axs[0].plot(observations.values[139:139*2], linestyle='--', color='red', linewidth=2)\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 2')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[1].set_title('Wind Direction')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(17, 12))\n",
    "# fig.suptitle('Source 1 Models Predictions vs Observations', fontsize=20)\n",
    "\n",
    "# axs[0].plot(estimated_y_hat[139*2:139*3])\n",
    "# axs[0].plot(SMITH_B_y_hat[139*2:139*3])\n",
    "# axs[0].plot(SMITH_C_y_hat[139*2:139*3])\n",
    "# axs[0].plot(SMITH_D_y_hat[139*2:139*3])\n",
    "# axs[0].plot(Briggs_A_y_hat[139*2:139*3])\n",
    "# axs[0].plot(Briggs_B_y_hat[139*2:139*3])\n",
    "# axs[0].plot(Briggs_C_y_hat[139*2:139*3])\n",
    "# axs[0].plot(Briggs_D_y_hat[139*2:139*3])\n",
    "# axs[0].plot(Briggs_E_y_hat[139*2:139*3])\n",
    "# axs[0].plot(Briggs_F_y_hat[139*2:139*3])\n",
    "# axs[0].plot(est_SMITH_y_hat[139*2:139*3])\n",
    "# axs[0].plot(observations.values[139*2:139*3], linestyle='--', color='red', linewidth=2)\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 3')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[1].set_title('Wind Direction')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(17, 12))\n",
    "# fig.suptitle('Source 1 Models Predictions vs Observations', fontsize=20)\n",
    "\n",
    "# axs[0].plot(estimated_y_hat[139*3:139*4])\n",
    "# axs[0].plot(SMITH_B_y_hat[139*3:139*4])\n",
    "# axs[0].plot(SMITH_C_y_hat[139*3:139*4])\n",
    "# axs[0].plot(SMITH_D_y_hat[139*3:139*4])\n",
    "# axs[0].plot(Briggs_A_y_hat[139*3:139*4])\n",
    "# axs[0].plot(Briggs_B_y_hat[139*3:139*4])\n",
    "# axs[0].plot(Briggs_C_y_hat[139*3:139*4])\n",
    "# axs[0].plot(Briggs_D_y_hat[139*3:139*4])\n",
    "# axs[0].plot(Briggs_E_y_hat[139*3:139*4])\n",
    "# axs[0].plot(Briggs_F_y_hat[139*3:139*4])\n",
    "# axs[0].plot(est_SMITH_y_hat[139*3:139*4])\n",
    "# axs[0].plot(observations.values[139*3:139*4], linestyle='--', color='red', linewidth=2)\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 4')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[1].set_title('Wind Direction')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(17, 12))\n",
    "# fig.suptitle('Source 1 Models Predictions vs Observations', fontsize=20)\n",
    "\n",
    "# axs[0].plot(estimated_y_hat[139*4:139*5])\n",
    "# axs[0].plot(SMITH_B_y_hat[139*4:139*5])\n",
    "# axs[0].plot(SMITH_C_y_hat[139*4:139*5])\n",
    "# axs[0].plot(SMITH_D_y_hat[139*4:139*5])\n",
    "# axs[0].plot(Briggs_A_y_hat[139*4:139*5])\n",
    "# axs[0].plot(Briggs_B_y_hat[139*4:139*5])\n",
    "# axs[0].plot(Briggs_C_y_hat[139*4:139*5])\n",
    "# axs[0].plot(Briggs_D_y_hat[139*4:139*5])\n",
    "# axs[0].plot(Briggs_E_y_hat[139*4:139*5])\n",
    "# axs[0].plot(Briggs_F_y_hat[139*4:139*5])\n",
    "# axs[0].plot(est_SMITH_y_hat[139*4:139*5])\n",
    "# axs[0].plot(observations.values[139*4:139*5], linestyle='--', color='red', linewidth=2)\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 5')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[1].set_title('Wind Direction')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(17, 12))\n",
    "# fig.suptitle('Source 1 Models Predictions vs Observations', fontsize=20)\n",
    "\n",
    "# axs[0].plot(estimated_y_hat[139*5:139*6])\n",
    "# axs[0].plot(SMITH_B_y_hat[139*5:139*6])\n",
    "# axs[0].plot(SMITH_C_y_hat[139*5:139*6])\n",
    "# axs[0].plot(SMITH_D_y_hat[139*5:139*6])\n",
    "# axs[0].plot(Briggs_A_y_hat[139*5:139*6])\n",
    "# axs[0].plot(Briggs_B_y_hat[139*5:139*6])\n",
    "# axs[0].plot(Briggs_C_y_hat[139*5:139*6])\n",
    "# axs[0].plot(Briggs_D_y_hat[139*5:139*6])\n",
    "# axs[0].plot(Briggs_E_y_hat[139*5:139*6])\n",
    "# axs[0].plot(Briggs_F_y_hat[139*5:139*6])\n",
    "# axs[0].plot(est_SMITH_y_hat[139*5:139*6])\n",
    "# axs[0].plot(observations.values[139*5:139*6], linestyle='--', color='red', linewidth=2)\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 6')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[1].set_title('Wind Direction')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(17, 12))\n",
    "# fig.suptitle('Source 1 Models Predictions vs Observations', fontsize=20)\n",
    "\n",
    "# axs[0].plot(estimated_y_hat[139*6:139*7])\n",
    "# axs[0].plot(SMITH_B_y_hat[139*6:139*7])\n",
    "# axs[0].plot(SMITH_C_y_hat[139*6:139*7])\n",
    "# axs[0].plot(SMITH_D_y_hat[139*6:139*7])\n",
    "# axs[0].plot(Briggs_A_y_hat[139*6:139*7])\n",
    "# axs[0].plot(Briggs_B_y_hat[139*6:139*7])\n",
    "# axs[0].plot(Briggs_C_y_hat[139*6:139*7])\n",
    "# axs[0].plot(Briggs_D_y_hat[139*6:139*7])\n",
    "# axs[0].plot(Briggs_E_y_hat[139*6:139*7])\n",
    "# axs[0].plot(Briggs_F_y_hat[139*6:139*7])\n",
    "# axs[0].plot(est_SMITH_y_hat[139*6:139*7])\n",
    "# axs[0].plot(observations.values[139*6:139*7], linestyle='--', color='red', linewidth=2)\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 7')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[1].set_title('Wind Direction')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(8, 1, figsize=(17, 25))\n",
    "# fig.suptitle('Source 2 Cumulative Absolute Error', fontsize=20)\n",
    "# plt.plot()\n",
    "# plt.plot()\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - estimated_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - SMITH_B_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - SMITH_C_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - SMITH_D_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - Briggs_A_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - Briggs_B_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - Briggs_C_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - Briggs_D_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - Briggs_E_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - Briggs_F_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].plot(np.cumsum(np.absolute(observations.values - est_SMITH_y_hat))[:wind_field.shape[0]])\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[0].set_title('Reflector 1')\n",
    "# axs[0].set_xlabel('Minutes')\n",
    "# axs[0].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - estimated_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - SMITH_B_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - SMITH_C_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - SMITH_D_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - Briggs_A_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - Briggs_B_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - Briggs_C_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - Briggs_D_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - Briggs_E_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - Briggs_F_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[1].plot(np.cumsum(np.absolute(observations.values - est_SMITH_y_hat))[wind_field.shape[0]:wind_field.shape[0]*2])\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[1].set_title('Reflector 2')\n",
    "# axs[1].set_xlabel('Minutes')\n",
    "# axs[1].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - estimated_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - SMITH_B_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - SMITH_C_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - SMITH_D_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - Briggs_A_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - Briggs_B_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - Briggs_C_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - Briggs_D_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - Briggs_E_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - Briggs_F_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[2].plot(np.cumsum(np.absolute(observations.values - est_SMITH_y_hat)[wind_field.shape[0]*2:wind_field.shape[0]*3]))\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[2].set_title('Reflector 3')\n",
    "# axs[2].set_xlabel('Minutes')\n",
    "# axs[2].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - estimated_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - SMITH_B_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - SMITH_C_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - SMITH_D_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - Briggs_A_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - Briggs_B_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - Briggs_C_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - Briggs_D_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - Briggs_E_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - Briggs_F_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[3].plot(np.cumsum(np.absolute(observations.values - est_SMITH_y_hat)[wind_field.shape[0]*3:wind_field.shape[0]*4]))\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[3].set_title('Reflector 4')\n",
    "# axs[3].set_xlabel('Minutes')\n",
    "# axs[3].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - estimated_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - SMITH_B_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - SMITH_C_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - SMITH_D_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - Briggs_A_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - Briggs_B_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - Briggs_C_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - Briggs_D_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - Briggs_E_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - Briggs_F_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[4].plot(np.cumsum(np.absolute(observations.values - est_SMITH_y_hat)[wind_field.shape[0]*4:wind_field.shape[0]*5]))\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[4].set_title('Reflector 5')\n",
    "# axs[4].set_xlabel('Minutes')\n",
    "# axs[4].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - estimated_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - SMITH_B_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - SMITH_C_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - SMITH_D_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - Briggs_A_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - Briggs_B_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - Briggs_C_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - Briggs_D_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - Briggs_E_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - Briggs_F_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[5].plot(np.cumsum(np.absolute(observations.values - est_SMITH_y_hat)[wind_field.shape[0]*5:wind_field.shape[0]*6]))\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[5].set_title('Reflector 6')\n",
    "# axs[5].set_xlabel('Minutes')\n",
    "# axs[5].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - estimated_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - SMITH_B_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - SMITH_C_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - SMITH_D_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - Briggs_A_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - Briggs_B_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - Briggs_C_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - Briggs_D_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - Briggs_E_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - Briggs_F_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[6].plot(np.cumsum(np.absolute(observations.values - est_SMITH_y_hat)[wind_field.shape[0]*6:wind_field.shape[0]*7]))\n",
    "# axs[0].legend(['estimated', 'SMITH B', 'SMITH C', 'SMITH D', 'Briggs A', 'Briggs B', 'Briggs C', 'Briggs D', 'Briggs E', 'Briggs F', 'estimated SMITH', 'Observations'])\n",
    "# axs[6].set_title('Reflector 7')\n",
    "# axs[6].set_xlabel('Minutes')\n",
    "# axs[6].set_ylabel('CH4 Measurements')\n",
    "\n",
    "# axs[7].plot(wind_field[\"Average Direction\"].values)\n",
    "# axs[7].set_title('Wind Direction')\n",
    "# axs[7].set_xlabel('Minutes')\n",
    "# axs[7].set_ylabel('Wind Direction')\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
